LangChain 是一个开发由语言模型驱动的应用程序的框架。我们相信最强大和不同的应用程序不仅会通过 API 调用语言模型， 还会：

#### 数据感知 : 将语言模型连接到其他数据源

#### 具有代理性质 : 允许语言模型与其环境交互

#### <u>模型（models）: LangChain 支持的各种模型类型和模型集成。</u>

**LLMs**：大型语言模型（LLMs)是我们首先介绍的模型类型。 这些模型将文本字符串作为输入，并返回文本字符串作为输出。

**聊天模型**：聊天模型是我们介绍的第二种模型类型。 这些模型通常由语言模型支持，但它们的API更加结构化。 具体来说，这些模型将聊天消息列表作为输入，并返回聊天消息。

**文本嵌入模型**：我们介绍的第三种模型类型是文本嵌入模型。 这些模型将文本作为输入，并返回一个浮点数列表。

#### <u>提示（prompts）: 编程模型的新方式是通过提示进行的。 “提示”指的是模型的输入。 这个输入很少是硬编码的，而是通常从多个组件构建而成的。 PromptTemplate负责构建这个输入。包括提示管理、提示优化和提示序列化。</u> 

#### 内存/记忆存储(memory ): 内存是在链/代理调用之间保持状态的概念。

默认情况下，Chains和Agents是无状态的，这意味着它们独立地处理每个传入的查询（就像底层的LLMs和聊天模型一样）。在某些应用程序中（聊天机器人是一个很好的例子），记住以前的交互非常重要，无论是在短期还是长期层面上。 “记忆”这个概念就是为了实现这一点。

LangChain以两种形式提供记忆内存 （Memory）组件。

首先，LangChain提供了管理和操作以前的聊天消息的辅助工具。这些工具被设计为模块化和有用的，无论如何使用它们都是如此。

类型：对话缓存窗口内存、实体摘要内存、对话知识图谱内存、对话摘要内存、对话摘要缓存内存、令牌缓冲区、基于向量存储的内存

#### <u>索引（indexes): 索引是指构造文档的方法，以便 LLM 可以最好地与它们交互。与您自己的文本数据结合使用时，语言模型往往更加强大—。</u>

在链中使用索引的最常见方式是“检索”步骤。这一步是指接受用户的查询并返回最相关的文档。我们之所以这样区分，是因为(1)索引可以用于检索之外的其他事情，(2)检索可以使用索引之外的其他逻辑来查找相关文档。因此，我们有一个“寻回者”接口的概念-这是大多数链工作的接口。

**1文档加载器**：如何从各种源加载文档。

通过文件回答问题包括四个步骤:

1. 创建索引    2.从该索引创建检索器。3.创建一个问题回答链   4. 问问题！

**2文本分割器：**

- 将文本拆分为小的、语义上有意义的块（通常是句子)。
- 开始将这些小块组合成一个较大的块，直到达到一定的大小（由某些函数测量)。
- 一旦达到该大小，将该块作为自己的文本块，然后开始创建一个新的文本块，其中包含一些重叠（以保持文本块之间的上下文)。

##### **3 向量存储VectorStores**：向量存储是构建索引的重要组成部分之一。

**4 检索器**：检索器接口是一种通用接口，使文档和语言模型易于组合。该接口公开一个get_relevant_documents方法，该方法接受查询（字符串)并返回文档列表。。

#### 链<u>（chains）: 链不仅仅是单个 LLM 调用，还包括一系列调用（无论是调用 LLM 还是不同的实用工具）。LangChain 提供了一种标准的链接口、许多与其他工具的集成。LangChain 提供了用于常见应用程序的端到端的链调用。</u>

通用功能：

异步链：LangChain通过利用asyncio库为链提供异步支持。目前LLMChain（通过arun、apredict、acall)、LLMMathChain（通过arun和acall)、ChatVectorDBChain以及QA chains支持异步方法。

###### 从LangChainHub加载：链会需要额外的参数，这些参数没有与链一起序列化。例如，对于在向量数据库上进行问题回答的链，将需要一个向量数据库

`LLMChain` 可能是查询 LLM 对象最流行的方式之一。它使用提供的输入键值（以及可用的内存键值)格式化提示模板，将格式化后的字符串传递给 LLM 并返回 LLM 输出。

顺序链：

- `SimpleSequentialChain`：最简单的顺序链形式，每个步骤都有一个单一的输入/输出，一个步骤的输出是下一个步骤的输入。
- `SequentialChain`：更一般的顺序链形式，允许多个输入/输出。

序列化：使用的序列化格式是json或yaml。目前仅有一些链支持此类型的序列化。我们将逐步增加支持的链数。

###### 转换链：将一个超长文本过滤为仅前3段，并将其传递到LLMChain以对其进行摘要。

#### <u>代理（agents）: 代理涉及 LLM 做出行动决策、执行该行动、查看一个观察结果，并重复该过程直到完成。</u>

##### 1工具：执行特定职责的函数。这可以是诸如：Google搜索、数据库查找、Python REPL、其他链等。工具的接口目前是期望有一个字符串作为输入，一个字符串作为输出的函数。

工具列表四要素：

- Tool Name 工具名称：LLM用来引用该工具的名称。
- Notes 工具描述：传递给LLM的工具描述。
- Requires LLM 注意事项：不传递给LLM的工具相关注意事项。
- (Optional) Extra Parameters（可选）附加参数：初始化此工具需要哪些额外参数。

##### 工具输入模式：默认情况下，工具通过检查函数签名来推断参数模式。为了更严格的要求，可以指定自定义输入模式，以及自定义验证逻辑。

##### 2 LLM：为代理提供动力的语言模型。

##### 3代理：要使用的代理。这应该是一个引用支持代理类的字符串。因为本教程专注于最简单、最高级别的API，所以只涵盖使用标准支持的代理。如果您想实现自定义代理（由二个部分组成：工具 tool：代理可以使用的工具，代理执行器 ：这决定了采取哪些行动。）。

代理执行器将代理和工具结合使用，并使用代理来决定调用哪些工具以及按什么顺序调用。

<u>**实例：**</u>

##### 1 带工具检索的自定义代理：

###### 流程：设置环境 -》设置工具 =〉工具检索器(tool-retriever) =》 提示模板 =〉 输出解析器 (Output Parser) =》设置LLM，停止序列和代理 =〉 使用代理（Use the Agent）

##### 2 自定义LLM代理（带有ChatModel）：由三个部分组成：

- PromptTemplate：这是用于指示语言模型该做什么的提示模板
- ChatModel：这是驱动代理的语言模型
- `stop`序列：指示LLM在找到此字符串时停止生成
- OutputParser：确定如何将LLM输出解析为AgentAction或AgentFinish对象。

LLMAgent用于代理执行器。这个代理执行器在很大程度上可以看作是一个循环：

1. 将用户输入和任何先前的步骤传递给代理（在这种情况下是LLMAgent）
2. 如果代理返回`AgentFinish`，则将其直接返回给用户。

##### 3. 自定义MRKL代理

- 工具：代理可用的工具。
- LLMChain：生成以一定方式解析的文本，以确定要采取哪个动作。
- 代理类本身：解析LLMChain的输出，以确定要采取哪个动作。

##### LangChain中可用的代理

- ###### `zero-shot-react-description`：此代理使用ReAct框架，仅基于工具的描述来确定要使用的工具）

  - ###### `react-docstore`：这个代理使用ReAct框架与文档存储进行交互。

- ###### `self-ask-with-search`：这个代理使用一个被命名为`Intermediate Answer`的工具。这个工具应该能够查找问题的事实性答案

- ###### `conversational-react-description`：这个代理程序旨在用于对话环境中。提示设计旨在使代理程序有助于对话

#### 用例

上述模块可以以多种方式使用。LangChain 还提供指导和帮助。以下是 LangChain 支持的一些常见用例。

######  [自治代理（autonomous agents）](https://www.langchain.com.cn/use_cases/autonomous_agents) : 长时间运行的代理会采取多步操作以尝试完成目标。 AutoGPT 和 BabyAGI就是典型代表。

###### [代理模拟（agent simulations）](https://www.langchain.com.cn/use_cases/agent_simulations) : 将代理置于封闭环境中观察它们如何相互作用，如何对事件作出反应，是观察它们长期记忆能力的有趣方法。

###### [个人助理（personal assistants）](https://www.langchain.com.cn/use_cases/personal_assistants) : 主要的 LangChain 使用用例。个人助理需要采取行动、记住交互并具有您的有关数据的知识。

###### [问答（question answering）](https://www.langchain.com.cn/use_cases/question_answering) : 第二个重大的 LangChain 使用用例。仅利用这些文档中的信息来构建答案，回答特定文档中的问题。

###### [聊天机器人（chatbots）](https://www.langchain.com.cn/use_cases/chatbots) : 由于语言模型擅长生成文本，因此它们非常适合创建聊天机器人。

###### [查询表格数据（tabular）](https://www.langchain.com.cn/use_cases/tabular) : 如果您想了解如何使用 LLM 查询存储在表格格式中的数据（csv、SQL、数据框等），请阅读此页面。

###### [代码理解（code）](https://www.langchain.com.cn/use_cases/code) : 如果您想了解如何使用 LLM 查询来自 GitHub 的源代码，请阅读此页面。

###### [与 API 交互（apis）](https://www.langchain.com.cn/use_cases/apis) : 使LLM 能够与 API 交互非常强大，以便为它们提供更实时的信息并允许它们采取行动。

###### [提取（extraction）](https://www.langchain.com.cn/use_cases/extraction) : 从文本中提取结构化信息。

###### [摘要（summarization）](https://www.langchain.com.cn/use_cases/summarization) : 将较长的文档汇总为更短、更简洁的信息块。一种数据增强生成的类型。

###### [评估（evaluation）](https://www.langchain.com.cn/use_cases/evaluation) : 生成模型是极难用传统度量方法评估的。 一种新的评估方式是使用语言模型本身进行评估。 LangChain 提供一些用于辅助评估的提示/链。

 

 